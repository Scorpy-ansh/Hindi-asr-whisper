<!-- HERO -->
<div align="center">
  <h1>ðŸŽ¤ Hindi-ASR-Whisper</h1>
  <p><b>Hindi speech-to-text with Whisper</b> Â· fine-tune & evaluate (WER/CER) Â· <b>Streamlit app</b> with MP3/WAV + mic Â· <b>Hindi â†’ English</b> translation Â· batch mode</p>

  <!-- Badges -->
  <p>
    <a href="https://github.com/Scorpy-ansh/Hindi-asr-whisper/stargazers">
      <img alt="Stars" src="https://img.shields.io/github/stars/Scorpy-ansh/Hindi-asr-whisper?style=flat&color=ffd166">
    </a>
    <a href="https://github.com/Scorpy-ansh/Hindi-asr-whisper/issues">
      <img alt="Issues" src="https://img.shields.io/github/issues/Scorpy-ansh/Hindi-asr-whisper?style=flat&color=ef476f">
    </a>
    <img alt="Python" src="https://img.shields.io/badge/python-3.10â€“3.12-118ab2">
    <img alt="PyTorch" src="https://img.shields.io/badge/PyTorch-2.x-ef3d60">
    <img alt="Transformers" src="https://img.shields.io/badge/Transformers-ðŸ¤—-9b5de5">
    <img alt="License" src="https://img.shields.io/badge/license-MIT-06d6a0">
  </p>

  <!-- Demo GIF (add later at docs/demo.gif) -->
  <img src="docs/demo.gif" alt="Demo" width="850">
</div>

---

## Table of Contents
- [âœ¨ Features](#-features)
- [ðŸ§  Whatâ€™s inside](#-whats-inside)
- [ðŸ§© Architecture](#-architecture)
- [ðŸš€ Quickstart](#-quickstart)
- [ðŸ§ª Evaluation](#-evaluation)
- [ðŸ–¥ï¸ App](#ï¸-app)
- [ðŸ“Š Results](#-results)
- [ðŸ“¦ Project structure](#-project-structure)
- [ðŸ™‹â€â™€ï¸ FAQ / Viva Short Answers](#ï¸-faq--viva-short-answers)
- [ðŸ™ Credits](#-credits)
- [ðŸ“ License](#-license)

---

## âœ¨ Features
- ðŸ—£ï¸ **Whisper Small (Hindi)** baseline + **fine-tuning** on Common Voice (v22)
- ðŸ“ˆ **WER / CER** with speaker-disjoint test split
- ðŸ§° Light **Hindi text normalization** (danda/quotes/spacing)
- ðŸ§ª **Feature visualizations** (spectrogram, token/length dists)
- ðŸŒ **Streamlit** app: MP3/WAV upload **or microphone**, Hindi transcript + **English translation**
- ðŸ“¦ **Batch mode**: many files â†’ CSV (optionally with references to compute WER/CER)
- âš™ï¸ Windows-friendly (no TensorFlow/JAX, MP3 via torchaudio)

---

## ðŸ§  Whatâ€™s inside
- **Model:** `collabora/whisper-small-hindi` (encoderâ€“decoder Transformer)  
- **Features:** 80-bin **log-Mel** spectrograms @ 16 kHz mono  
- **Training (demo):** AdamW, lr `5e-5`, grad clip `1.0`, small steps for CPU  
- **Translation:** MT (`Helsinki-NLP/opus-mt-hi-en`) or Whisper direct translate

---

## ðŸ§© Architecture
```mermaid
flowchart LR
  A[Audio (WAV/MP3 or Mic)] --> B[torchaudio load<br/>mono + 16 kHz]
  B --> C[Log-Mel (80Ã—T)]
  C --> D[Whisper Encoder]
  D --> E[Whisper Decoder]
  E --> F[Hindi Transcript]
  F -->|optional| G[MT hiâ†’en or Whisper translate]
  G --> H[English Text]
  F --> I[WER/CER vs Reference]
